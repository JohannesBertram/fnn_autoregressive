{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from different FNN layers\n",
    "\n",
    "Sampling from the output is not yet integrated here, use sampling-fnn-outputs.ipynb for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.11' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3.11 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from utils import createFlowDataset, subps  # Assuming these functions are in your utils module\n",
    "from glob import glob\n",
    "from time import time\n",
    "import sys\n",
    "\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "print(torch.__version__)  # E.g., '1.10.0'\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "import fnn\n",
    "from fnn import microns\n",
    "from numpy import full, concatenate\n",
    "from fnn.microns.build import frame_autoregressive_model\n",
    "\n",
    "checkpoint_dir = \"example_checkpoints\"\n",
    "latest_checkpoint_path, latest_epoch = get_latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "model = frame_autoregressive_model(pred_steps=pred_steps).to(device)\n",
    "model.load_state_dict(torch.load(latest_checkpoint_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "################# SET PARAMS ##########################\n",
    "block = ['blocks.2'] # choose from 'inputs.0', 'inputs.1', 'inputs.2', 'blocks.0', 'blocks.1', 'blocks.2', 'hidden', 'recurrent.out', 'position', 'readout'\n",
    "n_fmaps_to_sample = 40\n",
    "samples_per_fmap = 50\n",
    "seed = 3\n",
    "\n",
    "################## MORE PARAMS ########################\n",
    "# I suggest leaving these unchanged for comparability\n",
    "\n",
    "LAYER_TYPE = 'act'\n",
    "MAX_SIDE = 32\n",
    "\n",
    "# Flow stimuli parameters\n",
    "scl_factor = 0.7\n",
    "N_INSTANCES = 3\n",
    "trial_len = 75 // 2  # Number of frames\n",
    "stride = 1\n",
    "\n",
    "model_name = 'fnn07'\n",
    "\n",
    "## SAMPLING\n",
    "fmap_samp_method = 'maxFr'\n",
    "samp_max_one_dir = False # samples high activities to horizontal movement to the right only if set to True\n",
    "neur_samp_method = 'maxNr'\n",
    "\n",
    "input_shape = (144, 256)\n",
    "save_hidden = False # hacky hidden state debugging\n",
    "\n",
    "get_pos = True if \"position\" in block else False\n",
    "if get_pos:\n",
    "    block[block == \"position\"] = 'recurrent.out'\n",
    "\n",
    "get_act = any(item in block for item in ['inputs.0', 'inputs.1', 'inputs.2', 'blocks.0', 'blocks.1', 'blocks.2'])\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total number of parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in model.named_modules():\n",
    "    print(f\"Module name: {name}, type: {type(module).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.readout.feature.weights[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readout1 = model.readout.feature.weights[0][:, 0, :].cpu().detach().numpy()\n",
    "readout2 = model.readout.feature.weights[0][:, 0, :].cpu().detach().numpy()\n",
    "readout3 = model.readout.feature.weights[0][:, 0, :].cpu().detach().numpy()\n",
    "readout4 = model.readout.feature.weights[0][:, 0, :].cpu().detach().numpy()\n",
    "\n",
    "weights = np.concatenate([readout1, readout2, readout3, readout4], axis=1)\n",
    "print(weights.shape)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_decoding = PCA(n_components=5)\n",
    "pca_decoding_result = pca_decoding.fit_transform(\n",
    "    weights\n",
    ")\n",
    "\n",
    "print(pca_decoding_result.shape)\n",
    "\n",
    "plt.scatter(pca_decoding_result[:1000, 0], pca_decoding_result[:1000, 1])\n",
    "plt.show()\n",
    "\n",
    "#reshaped_decoding_result = pca_decoding_result.reshape(11*8, -1)\n",
    "\n",
    "#plt.plot(model.readout.feature.weights[0][:, 0, :].cpu().detach().numpy())\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_y_pos = np.tanh(model.readout.position.mean[:].cpu().detach().numpy())\n",
    "#np.save(\"x_y_pos.npy\", x_y_pos)\n",
    "plt.scatter((x_y_pos[:, 0]+1)*12, (x_y_pos[:, 1]+1)*8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_sample(batch_size=1):\n",
    "\n",
    "    units = 9941\n",
    "\n",
    "    mu = Parameter(torch.zeros(units, 2))\n",
    "    mu.scale = units\n",
    "    mu.decay = False\n",
    "\n",
    "    sigma = Parameter(torch.eye(2).repeat(units, 1, 1))\n",
    "    sigma.scale = units\n",
    "    sigma.decay = False\n",
    "\n",
    "\n",
    "    x = mu.repeat(batch_size, 1, 1)\n",
    "    x = x + torch.einsum(\"U C D , N U D -> N U C\", sigma, torch.randn_like(x))\n",
    "\n",
    "    return x\n",
    "\n",
    "def process_core_output(core):\n",
    "    #position = torch.load(\"test_pos.pt\")\n",
    "    #self.position.mean.expand(core.size(0), -1, -1)\n",
    "    #print(\"here\")\n",
    "    out = torch.nn.functional.grid_sample(\n",
    "        core,\n",
    "        grid = torch.nn.functional.tanh(model.readout.position.mean.expand(core.size(0), -1, -1)).unsqueeze(dim=2),\n",
    "        mode = \"bilinear\",\n",
    "        padding_mode=\"border\",\n",
    "        align_corners=False\n",
    "    )\n",
    "    return out\n",
    "\n",
    "#process_core_output(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# COLLECT LAYERS #################\n",
    "\n",
    "# Function to get layers by name and type\n",
    "def get_layers_by_name_and_type(model, substrings, layer_types):\n",
    "    layers = []\n",
    "    for name, module in model.named_modules():\n",
    "        if any(sub in name for sub in substrings):\n",
    "            if isinstance(module, fnn.model.elements.Conv) and (\"skips\" not in name) and (\"convs.1\" not in name):\n",
    "                layers.append((name, module))\n",
    "    return layers\n",
    "\n",
    "# Collect layers based on the LAYER_TYPE and block\n",
    "if LAYER_TYPE == 'act':\n",
    "    layer_types = (nn.ReLU,)\n",
    "elif LAYER_TYPE == 'conv':\n",
    "    layer_types = (nn.Conv2d,)\n",
    "elif LAYER_TYPE == 'dense':\n",
    "    layer_types = (nn.Linear,)\n",
    "else:\n",
    "    raise ValueError('Invalid LAYER_TYPE')\n",
    "\n",
    "layer_types = 'Conv'\n",
    "\n",
    "layers_to_use = get_layers_by_name_and_type(model, block, layer_types)\n",
    "\n",
    "if 'hidden' in block:\n",
    "    layers_to_use.append((\"hidden\", model.core.recurrent))\n",
    "if 'interpolation' in block:\n",
    "    layers_to_use.append((\"interpolation\", model.readout.position))\n",
    "if 'readout' in block:\n",
    "    layers_to_use.append((\"readout\", model.readout))\n",
    "if 'perspective' in block:\n",
    "    layers_to_use = [(\"perspective\", model.perspective)]\n",
    "\n",
    "Nlayers = len(layers_to_use)\n",
    "print(f'Number of layers to use: {Nlayers}')\n",
    "\n",
    "\n",
    "# Set up hooks to capture activations\n",
    "activation_outputs = {}\n",
    "\n",
    "BATCH_SIZE=1\n",
    "counter = 0\n",
    "def get_activation(name):\n",
    "    print(name)\n",
    "\n",
    "    if name == \"hidden\":\n",
    "        def hook(model, input, output):\n",
    "            \n",
    "            if hasattr(module, 'past') and module.past is not None:\n",
    "                if isinstance(module.past, dict):\n",
    "                    \n",
    "                    if not name in activation_outputs:\n",
    "                        activation_outputs[name] = {}\n",
    "                    global counter\n",
    "                    activation_outputs[\"hidden\"][counter] = module.past[\"h\"].clone()\n",
    "                    #print(activation_outputs[\"hidden\"][counter].shape)\n",
    "                    #activation_outputs[\"hidden\"][counter] = activation_outputs[\"hidden\"][counter].clone()[:, :, :, 4:-4]\n",
    "                    #print(\"new\")\n",
    "                    #print(activation_outputs[\"hidden\"][counter].shape)\n",
    "                    global layers_to_use\n",
    "                    if name == layers_to_use[-1][0]:\n",
    "                        \n",
    "                        counter += 1\n",
    "                        counter = counter % 37\n",
    "    else:\n",
    "        def hook(model, input, output):\n",
    "            act_fct = torch.nn.GELU()\n",
    "            \n",
    "            if not name in activation_outputs:\n",
    "                activation_outputs[name] = {}\n",
    "            global counter\n",
    "            if name == \"core.recurrent.out\" and get_pos:\n",
    "                activation_outputs[name][counter] = process_core_output(output.detach())\n",
    "            else:\n",
    "                activation_outputs[name][counter] = output.detach()\n",
    "\n",
    "            if get_act:\n",
    "                activation_outputs[name][counter] = act_fct(activation_outputs[name][counter]) * 1.7015043497085571\n",
    "           \n",
    "            global layers_to_use\n",
    "            #print(f\"{counter}, {name}\")\n",
    "            if name == layers_to_use[-1][0]:\n",
    "                \n",
    "                counter += 1\n",
    "                counter = counter % 37\n",
    "\n",
    "    return hook\n",
    "\n",
    "for name, module in layers_to_use:\n",
    "    if name == \"hidden\":\n",
    "        \n",
    "        model.core.recurrent.register_forward_hook(get_activation(name))\n",
    "\n",
    "    else:\n",
    "        module.register_forward_hook(get_activation(name))\n",
    "\n",
    "frames = concatenate([\n",
    "    full(shape=[2, 144, 256], dtype=\"uint8\", fill_value=0),   # 1 second of black\n",
    "    full(shape=[2, 144, 256], dtype=\"uint8\", fill_value=128), # 1 second of gray\n",
    "    full(shape=[2, 144, 256], dtype=\"uint8\", fill_value=255), # 1 second of white\n",
    "])\n",
    "\n",
    "with torch.no_grad():\n",
    "    response = model.predict(stimuli=frames)\n",
    "\n",
    "\n",
    "# Collect output shapes and compute pads\n",
    "MAX_SIDE = 32\n",
    "all_layer_totfmaps = []\n",
    "all_layer_spacedims = []\n",
    "out_pads = []\n",
    "for name, module in layers_to_use:\n",
    "    output = activation_outputs[name][0]\n",
    "    #print(\"here\")\n",
    "    print(output.shape)\n",
    "    if \"interpolation\" in name or \"recurrent\" in name or 'readout' in name:\n",
    "        pad = False\n",
    "    else:\n",
    "        pad = True\n",
    "\n",
    "    if not pad:\n",
    "        output = output[:, :40]\n",
    "    batch_size, channels, height, width = output.shape\n",
    "    print(batch_size, channels, height, width)\n",
    "    totfmaps = channels\n",
    "\n",
    "    \n",
    "    if pad:\n",
    "        out_pad = height // 4 #max(1, (height - MAX_SIDE) // 2) * 3\n",
    "        print(out_pad)\n",
    "        h = height - out_pad\n",
    "        w = width - out_pad\n",
    "    else:\n",
    "        out_pad = 0\n",
    "        h = height\n",
    "        w = width\n",
    "        output = 0\n",
    "\n",
    "    spacedims = [h, w, totfmaps]\n",
    "    all_layer_totfmaps.append(totfmaps)\n",
    "    all_layer_spacedims.append(spacedims)\n",
    "    out_pads.append(out_pad)\n",
    "\n",
    "all_layer_nunits = [np.prod(lspcd) for lspcd in all_layer_spacedims]\n",
    "\n",
    "for li, (name, module) in enumerate(layers_to_use):\n",
    "    print(f'{name}: {all_layer_totfmaps[li]} feature maps')\n",
    "    print('  spacedims', all_layer_spacedims[li])\n",
    "    print('  Total units:', all_layer_nunits[li], flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############# LOAD FLOW STIM FRAMES #################\n",
    "counter = 0\n",
    "orig_shape = (800, 600)\n",
    "\n",
    "mydirs = list(map(str, range(0, 360, 45)))\n",
    "categories = ['grat_W12', 'grat_W1', 'grat_W2',\n",
    "              'neg1dotflow_D1_bg', 'neg3dotflow_D1_bg', 'neg1dotflow_D2_bg', 'neg3dotflow_D2_bg',\n",
    "              'pos1dotflow_D1_bg', 'pos3dotflow_D1_bg', 'pos1dotflow_D2_bg', 'pos3dotflow_D2_bg']\n",
    "\n",
    "topdir = 'flowstims'\n",
    "NDIRS = len(mydirs)\n",
    "tot_stims = len(categories) * NDIRS\n",
    "print('tot_stims', tot_stims, flush=True)\n",
    "frames_per_stim = (trial_len // stride)\n",
    "print('frames_per_stim', frames_per_stim)\n",
    "\n",
    "# Create flow datasets (placeholder function)\n",
    "flow_datasets = createFlowDataset(categories, topdir, mydirs, orig_shape, input_shape,\n",
    "                                  scl_factor, N_INSTANCES, trial_len, stride)\n",
    "\n",
    "# Show example of sequence of frames generated for a stimulus trial\n",
    "n_frames_to_show = 4\n",
    "interval = 37\n",
    "\n",
    "f, axes = subps(1, n_frames_to_show, 1, 1)\n",
    "for i in range(n_frames_to_show):\n",
    "    ax = axes[i]\n",
    "    img = flow_datasets[0][i * interval].reshape(input_shape)\n",
    "    ax.imshow(img, vmin=0, vmax=255, cmap='gray')\n",
    "    ax.axis('off')\n",
    "\n",
    "f.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flow_datasets[0].shape)\n",
    "print(144*256)\n",
    "print(3256 / 8 / 37)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def reshape_flow_img(raveled_1chan_img):\n",
    "    img = raveled_1chan_img.reshape((37, input_shape[0], input_shape[1]))\n",
    "    #img = np.stack([img, img, img], axis=0)  # Convert to 3 channels\n",
    "    img = img.astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Collect output shapes and compute pads\n",
    "MAX_SIDE = 16\n",
    "all_layer_totfmaps = []\n",
    "all_layer_spacedims = []\n",
    "out_pads = []\n",
    "for name, module in layers_to_use:\n",
    "    for seq_idx in range(int(len(flow_datasets[0])/37)):\n",
    "        sequence = reshape_flow_img(flow_datasets[0][seq_idx*37:(seq_idx+1)*37])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            response = model.predict(stimuli=sequence)\n",
    "        for i in range(37):\n",
    "            output = activation_outputs[name][i]\n",
    "            plt.imshow(output.cpu()[0, 0], cmap=\"Grays\")\n",
    "            plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################### COMPUTE ################\n",
    "\n",
    "def reshape_flow_img(raveled_1chan_img):\n",
    "    img = raveled_1chan_img.reshape((37, input_shape[0], input_shape[1]))\n",
    "    #img = np.stack([img, img, img], axis=0)  # Convert to 3 channels\n",
    "    img = img.astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "\n",
    "TOL = 0\n",
    "\n",
    "n_orig_imgs = tot_stims\n",
    "n_shifts = frames_per_stim\n",
    "n_shifted_imgs = n_orig_imgs * n_shifts\n",
    "\n",
    "\n",
    "print('tot # of images:', n_orig_imgs, '*', n_shifts, '=', n_shifted_imgs)\n",
    "\n",
    "\n",
    "layer_outputs = []\n",
    "instance_layer_outputs = []\n",
    "\n",
    "for li in range(len(layers_to_use)):\n",
    "    shape = [n_shifted_imgs] + all_layer_spacedims[li]\n",
    "    layer_outputs.append(np.zeros(shape, dtype='float32'))\n",
    "    shape_inst = np.append([N_INSTANCES], shape)\n",
    "    instance_layer_outputs.append(np.zeros(shape_inst, dtype='float32'))\n",
    "\n",
    "for insti in range(N_INSTANCES):\n",
    "    extX = flow_datasets[insti]\n",
    "    assert extX.shape[0] == n_shifted_imgs\n",
    "\n",
    "    print('INSTANCE', insti)\n",
    "    start0 = time()\n",
    "    layer_output = []\n",
    "    for li in range(len(layers_to_use)):\n",
    "        layer_output.append([])\n",
    "\n",
    "    for seq_idx in range(int(len(extX)/37)):\n",
    "        start = time()\n",
    "        #print(bb, end=' ', flush=True)\n",
    "\n",
    "        # Prepare batch\n",
    "        sequence = extX[seq_idx*37:(seq_idx+1)*37]\n",
    "        sequence = reshape_flow_img(extX[seq_idx*37:(seq_idx+1)*37])\n",
    "\n",
    "\n",
    "        # Collect outputs per layer\n",
    "        activation_outputs.clear()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            _ = model.predict(stimuli=sequence)\n",
    "\n",
    "        # Collect outputs per layer\n",
    "        for li, (name, module) in enumerate(layers_to_use):\n",
    "            for t in range(trial_len):\n",
    "                output = activation_outputs[name][t].detach().cpu().numpy()\n",
    "                if not pad:\n",
    "                    output = output[:, :40]\n",
    "                #print(output.shape)\n",
    "                #print(all_layer_spacedims[li])\n",
    "                # Crop the output if needed\n",
    "                h, w, c = all_layer_spacedims[li]\n",
    "                out_pad = out_pads[li]\n",
    "                #print(out_pad)\n",
    "                if output.ndim == 4:\n",
    "                    # output shape: (batch_size, channels, height, width)\n",
    "                    output_cropped = output[:, :, out_pad: out_pad + h, out_pad: out_pad + w]\n",
    "                    # Rearrange to (batch_size, height, width, channels)\n",
    "                    output_cropped = np.transpose(output_cropped, (0, 2, 3, 1))\n",
    "                else:\n",
    "                    output_cropped = output  # For dense layers\n",
    "\n",
    "                #print(output_cropped.shape)\n",
    "\n",
    "                layer_output[li].append(output_cropped)\n",
    "\n",
    "        print('(%.1fs) ' % (time() - start), end='', flush=True)\n",
    "    print(' Tot time = %.1f' % (time() - start0), flush=True)\n",
    "\n",
    "    # After processing all batches for this instance, concatenate outputs\n",
    "    for li in range(len(layers_to_use)):\n",
    "        #print(li)\n",
    "        #print([l.shape for l in layer_output[li]])\n",
    "        layer_output[li] = np.concatenate(layer_output[li], axis=0)\n",
    "        layer_outputs[li] += layer_output[li]\n",
    "        instance_layer_outputs[li][insti] = layer_output[li]\n",
    "\n",
    "\n",
    "# Average over instances\n",
    "for li in range(len(layers_to_use)):\n",
    "    layer_outputs[li] /= N_INSTANCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if layers_to_use[-1][0] == \"hidden\" and save_hidden:\n",
    "    np.save(\"../data/hidden_states.npy\", layer_outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### SUMMARIZE ACTIVITY ###########\n",
    "\n",
    "print('Activities per img:', end=' ')\n",
    "all_neurons_maxs = []\n",
    "all_neurons_means = []\n",
    "all_per_img_output = []\n",
    "for li in range(len(layers_to_use)):\n",
    "    print(li, end='', flush=True)\n",
    "    layer_output_ = layer_outputs[li].copy()\n",
    "\n",
    "\n",
    "    layer_output_[layer_output_ < 0] = 0\n",
    "\n",
    "    nfmaps = layer_output_.shape[3]\n",
    "    # Reshape to [n_orig_imgs, n_shifts, nfmaps, -1]\n",
    "    orig_per_img_output = np.moveaxis(layer_output_, -1, 1).reshape([n_orig_imgs, n_shifts, nfmaps, -1])\n",
    "    orig_per_img_output = np.moveaxis(orig_per_img_output, 1, -1)\n",
    "\n",
    "\n",
    "\n",
    "    # Normalize each image by the max\n",
    "    layer_output_ /= np.maximum(layer_output_.max((1, 2, 3), keepdims=True), 1e-8)\n",
    "\n",
    "    per_img_output = np.moveaxis(layer_output_, -1, 1).reshape([n_orig_imgs, n_shifts, nfmaps, -1])\n",
    "    per_img_output = np.moveaxis(per_img_output, 1, -1)\n",
    "\n",
    "    tot_n_neurons = np.prod(layer_output_.shape[1:])\n",
    "\n",
    "    neurons_maxs = np.zeros(per_img_output.shape[1:3])\n",
    "    neurons_means = np.zeros(per_img_output.shape[1:3])\n",
    "\n",
    "    for imi in range(n_orig_imgs):\n",
    "\n",
    "        if samp_max_one_dir and imi % NDIRS > 0:\n",
    "            im_avgs = 0\n",
    "        else:\n",
    "            im_avgs = per_img_output[imi].mean(2)  # Averaging across time\n",
    "        neurons_maxs = np.maximum(neurons_maxs, im_avgs)\n",
    "        neurons_means += im_avgs\n",
    "        \n",
    "    neurons_means /= n_orig_imgs\n",
    "\n",
    "    idxs = neurons_maxs.mean(1).argsort()\n",
    "\n",
    "    if li == 0:\n",
    "        all_neurons_maxs = neurons_maxs\n",
    "        all_neurons_means = neurons_means\n",
    "        all_per_img_output = orig_per_img_output\n",
    "    else:\n",
    "        all_neurons_maxs = np.concatenate([all_neurons_maxs, neurons_maxs], 0)\n",
    "        all_neurons_means = np.concatenate([all_neurons_means, neurons_means], 0)\n",
    "        all_per_img_output = np.concatenate([all_per_img_output, orig_per_img_output], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# SAMPLE NEURONS ###########\n",
    "\n",
    "nfmaps, n_neurons_per_fmap = all_neurons_maxs.shape\n",
    "layer_is_per_fmap = np.concatenate([li * np.ones(nf) for li, nf in enumerate(all_layer_totfmaps)])\n",
    "np.random.seed(seed)\n",
    "\n",
    "maxsmean = all_neurons_maxs.mean(1)\n",
    "nonzero_indices = (~np.isclose(maxsmean, 0)).sum()\n",
    "n_fmaps_to_sample_ = min(n_fmaps_to_sample, nonzero_indices)\n",
    "print(n_fmaps_to_sample)\n",
    "if fmap_samp_method == 'maxFr':\n",
    "    probabilities = maxsmean / maxsmean.sum()\n",
    "    top_fmaps = np.random.choice(range(nfmaps), n_fmaps_to_sample_, replace=False, p=probabilities)\n",
    "elif fmap_samp_method == \"random\":\n",
    "    top_fmaps = np.random.choice(range(nfmaps), n_fmaps_to_sample_, replace=False) \n",
    "else:\n",
    "    raise ValueError('Invalid fmap_samp_method')\n",
    "\n",
    "# Pick active neurons in each of these feature maps\n",
    "sampled_neurons = []\n",
    "\n",
    "samples_per_fmap = min(samples_per_fmap, all_neurons_means.shape[1])\n",
    "print(samples_per_fmap)\n",
    "for fi in top_fmaps:\n",
    "    if neur_samp_method == 'maxNr':\n",
    "        neuron_vals = all_neurons_maxs[fi]\n",
    "        nonzero_neurons = (~np.isclose(neuron_vals, 0)).sum()\n",
    "        samples_per_fmap_ = min(samples_per_fmap, nonzero_neurons)\n",
    "        probabilities = neuron_vals / neuron_vals.sum()\n",
    "        top_nis = np.random.choice(range(n_neurons_per_fmap), samples_per_fmap_, replace=False, p=probabilities)\n",
    "    else:\n",
    "        raise ValueError('Invalid neur_samp_method')\n",
    "    sampled_neurons += list(fi * n_neurons_per_fmap + top_nis)\n",
    "sampled_neurons = np.array(sampled_neurons)\n",
    "n_neurons_to_pick = len(sampled_neurons)\n",
    "print(n_neurons_to_pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######### BUILD TENSOR ##########\n",
    "\n",
    "def get_neuron_pos(ni):\n",
    "    \"\"\"From sampled indices ni, get original indices back (layer index, fmap, posi, posj, raveled_idx)\"\"\"\n",
    "    fi = ni // n_neurons_per_fmap\n",
    "    li = int(layer_is_per_fmap[fi])\n",
    "    ij = ni % n_neurons_per_fmap\n",
    "    h, w, _ = all_layer_spacedims[li]\n",
    "    ii = ij // w\n",
    "    jj = ij % w\n",
    "    return li, fi, ii, jj, ij\n",
    "\n",
    "assert n_orig_imgs // NDIRS == len(categories)\n",
    "\n",
    "tensorX = np.zeros((n_neurons_to_pick, len(categories), NDIRS, n_shifts))\n",
    "neurons_used = np.empty((n_neurons_to_pick, 5), dtype='int')\n",
    "\n",
    "# Collect PSTs for those sampled neurons\n",
    "for nii, ni in enumerate(sampled_neurons):\n",
    "    li, fi, ii, jj, posi = get_neuron_pos(ni)\n",
    "    neurons_used[nii] = [li, fi, ii, jj, posi]\n",
    "\n",
    "    for cati in range(len(categories)):\n",
    "        pst = all_per_img_output[cati * NDIRS: (cati + 1) * NDIRS, fi, posi, :]\n",
    "        tensorX[nii, cati] = pst\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import mannwhitneyu, ks_2samp\n",
    "\n",
    "def compare_weight_distributions(selected_weights, other_weights):\n",
    "    \"\"\"\n",
    "    Compare two weight distributions to test if selected_weights are smaller than other_weights.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    selected_weights : array-like\n",
    "        First group of weights (hypothesized to be smaller)\n",
    "    other_weights : array-like\n",
    "        Second group of weights (hypothesized to be larger)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing test results and statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to numpy arrays and flatten\n",
    "    selected_weights = np.array(selected_weights).flatten()\n",
    "    other_weights = np.array(other_weights).flatten()\n",
    "    \n",
    "    # Remove any NaN values\n",
    "    selected_weights = selected_weights[~np.isnan(selected_weights)]\n",
    "    other_weights = other_weights[~np.isnan(other_weights)]\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"WEIGHT DISTRIBUTION COMPARISON ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Basic descriptive statistics\n",
    "    print(\"\\n1. DESCRIPTIVE STATISTICS\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Selected weights (n={len(selected_weights)}):\")\n",
    "    print(f\"  Mean: {np.mean(selected_weights):.4f}\")\n",
    "    print(f\"  Median: {np.median(selected_weights):.4f}\")\n",
    "    print(f\"  Std: {np.std(selected_weights):.4f}\")\n",
    "    print(f\"  Min: {np.min(selected_weights):.4f}\")\n",
    "    print(f\"  Max: {np.max(selected_weights):.4f}\")\n",
    "    print(f\"  25th percentile: {np.percentile(selected_weights, 25):.4f}\")\n",
    "    print(f\"  75th percentile: {np.percentile(selected_weights, 75):.4f}\")\n",
    "    \n",
    "    print(f\"\\nOther weights (n={len(other_weights)}):\")\n",
    "    print(f\"  Mean: {np.mean(other_weights):.4f}\")\n",
    "    print(f\"  Median: {np.median(other_weights):.4f}\")\n",
    "    print(f\"  Std: {np.std(other_weights):.4f}\")\n",
    "    print(f\"  Min: {np.min(other_weights):.4f}\")\n",
    "    print(f\"  Max: {np.max(other_weights):.4f}\")\n",
    "    print(f\"  25th percentile: {np.percentile(other_weights, 25):.4f}\")\n",
    "    print(f\"  75th percentile: {np.percentile(other_weights, 75):.4f}\")\n",
    "    \n",
    "    # Difference in means and medians\n",
    "    mean_diff = np.mean(selected_weights) - np.mean(other_weights)\n",
    "    median_diff = np.median(selected_weights) - np.median(other_weights)\n",
    "    \n",
    "    print(f\"\\nDifference (Selected - Other):\")\n",
    "    print(f\"  Mean difference: {mean_diff:.4f}\")\n",
    "    print(f\"  Median difference: {median_diff:.4f}\")\n",
    "    \n",
    "    # Test for normality\n",
    "    print(\"\\n2. NORMALITY TESTS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Shapiro-Wilk test (good for smaller samples)\n",
    "    if len(selected_weights) <= 5000:\n",
    "        shapiro_selected = stats.shapiro(selected_weights)\n",
    "        print(f\"Selected weights - Shapiro-Wilk: p-value = {shapiro_selected.pvalue:.4f}\")\n",
    "        print(f\"  {'Normal' if shapiro_selected.pvalue > 0.05 else 'Non-normal'} distribution\")\n",
    "    \n",
    "    if len(other_weights) <= 5000:\n",
    "        shapiro_other = stats.shapiro(other_weights)\n",
    "        print(f\"Other weights - Shapiro-Wilk: p-value = {shapiro_other.pvalue:.4f}\")\n",
    "        print(f\"  {'Normal' if shapiro_other.pvalue > 0.05 else 'Non-normal'} distribution\")\n",
    "    \n",
    "    # Kolmogorov-Smirnov test for normality (better for larger samples)\n",
    "    ks_selected = stats.kstest(selected_weights, 'norm', args=(np.mean(selected_weights), np.std(selected_weights)))\n",
    "    ks_other = stats.kstest(other_weights, 'norm', args=(np.mean(other_weights), np.std(other_weights)))\n",
    "    \n",
    "    print(f\"\\nKolmogorov-Smirnov test against normal distribution:\")\n",
    "    print(f\"Selected weights: p-value = {ks_selected.pvalue:.4f}\")\n",
    "    print(f\"Other weights: p-value = {ks_other.pvalue:.4f}\")\n",
    "    \n",
    "    # Hypothesis testing\n",
    "    print(\"\\n3. HYPOTHESIS TESTING\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"H0: Selected weights >= Other weights\")\n",
    "    print(\"H1: Selected weights < Other weights (one-tailed test)\")\n",
    "    \n",
    "    # Mann-Whitney U test (non-parametric, good for non-normal data)\n",
    "    mw_statistic, mw_pvalue = mannwhitneyu(selected_weights, other_weights, alternative='less')\n",
    "    print(f\"\\nMann-Whitney U test (non-parametric):\")\n",
    "    print(f\"  Statistic: {mw_statistic:.4f}\")\n",
    "    print(f\"  p-value: {mw_pvalue:.4f}\")\n",
    "    print(f\"  Result: {'Reject H0' if mw_pvalue < 0.05 else 'Fail to reject H0'}\")\n",
    "    print(f\"  Conclusion: {'Selected weights are significantly smaller' if mw_pvalue < 0.05 else 'No significant difference'}\")\n",
    "    \n",
    "    # Welch's t-test (handles unequal variances)\n",
    "    t_statistic, t_pvalue = stats.ttest_ind(selected_weights, other_weights, equal_var=False)\n",
    "    t_pvalue_one_tailed = t_pvalue / 2 if t_statistic < 0 else 1 - t_pvalue / 2\n",
    "    \n",
    "    print(f\"\\nWelch's t-test (parametric, unequal variances):\")\n",
    "    print(f\"  t-statistic: {t_statistic:.4f}\")\n",
    "    print(f\"  p-value (one-tailed): {t_pvalue_one_tailed:.4f}\")\n",
    "    print(f\"  Result: {'Reject H0' if t_pvalue_one_tailed < 0.05 else 'Fail to reject H0'}\")\n",
    "    \n",
    "    # Kolmogorov-Smirnov two-sample test\n",
    "    ks2_statistic, ks2_pvalue = ks_2samp(selected_weights, other_weights)\n",
    "    print(f\"\\nKolmogorov-Smirnov two-sample test:\")\n",
    "    print(f\"  Statistic: {ks2_statistic:.4f}\")\n",
    "    print(f\"  p-value: {ks2_pvalue:.4f}\")\n",
    "    print(f\"  Result: {'Distributions are significantly different' if ks2_pvalue < 0.05 else 'No significant difference'}\")\n",
    "    \n",
    "    # Effect size (Cohen's d)\n",
    "    pooled_std = np.sqrt(((len(selected_weights) - 1) * np.var(selected_weights) + \n",
    "                         (len(other_weights) - 1) * np.var(other_weights)) / \n",
    "                        (len(selected_weights) + len(other_weights) - 2))\n",
    "    cohens_d = (np.mean(selected_weights) - np.mean(other_weights)) / pooled_std\n",
    "    \n",
    "    print(f\"\\nEffect size (Cohen's d): {cohens_d:.4f}\")\n",
    "    if abs(cohens_d) < 0.2:\n",
    "        effect_size_desc = \"negligible\"\n",
    "    elif abs(cohens_d) < 0.5:\n",
    "        effect_size_desc = \"small\"\n",
    "    elif abs(cohens_d) < 0.8:\n",
    "        effect_size_desc = \"medium\"\n",
    "    else:\n",
    "        effect_size_desc = \"large\"\n",
    "    print(f\"Effect size interpretation: {effect_size_desc}\")\n",
    "    \n",
    "    # Plotting\n",
    "    print(\"\\n4. GENERATING PLOTS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Histograms\n",
    "    axes[0, 0].hist(selected_weights, bins=30, alpha=0.7, label='Potentially Inhibitory', color='skyblue', density=True)\n",
    "    axes[0, 0].hist(other_weights, bins=30, alpha=0.7, label='Other', color='lightcoral', density=True)\n",
    "    axes[0, 0].set_xlabel('Weight values')\n",
    "    axes[0, 0].set_ylabel('Density')\n",
    "    axes[0, 0].set_title('Weight Value Histogram')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Box plots\n",
    "    data_to_plot = [selected_weights, other_weights]\n",
    "    box_plot = axes[0, 1].boxplot(data_to_plot, labels=['Inhibitory', 'Other'], patch_artist=True)\n",
    "    box_plot['boxes'][0].set_facecolor('skyblue')\n",
    "    box_plot['boxes'][1].set_facecolor('lightcoral')\n",
    "    axes[0, 1].set_ylabel('Weight values')\n",
    "    axes[0, 1].set_title('Box Plot Comparison')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Violin plots\n",
    "    axes[1, 0].violinplot([selected_weights, other_weights], positions=[1, 2], showmeans=True, showmedians=True)\n",
    "    axes[1, 0].set_xticks([1, 2])\n",
    "    axes[1, 0].set_xticklabels(['Selected', 'Other'])\n",
    "    axes[1, 0].set_ylabel('Weight values')\n",
    "    axes[1, 0].set_title('Violin Plot Comparison')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Q-Q plot\n",
    "    from scipy.stats import probplot\n",
    "    combined_data = np.concatenate([selected_weights, other_weights])\n",
    "    probplot(selected_weights, dist=\"norm\", plot=axes[1, 1])\n",
    "    axes[1, 1].set_title('Q-Q Plot: Selected Weights vs Normal Distribution')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n5. SUMMARY\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Sample sizes: Selected={len(selected_weights)}, Other={len(other_weights)}\")\n",
    "    print(f\"Mean difference: {mean_diff:.4f}\")\n",
    "    print(f\"Mann-Whitney U p-value: {mw_pvalue:.4f}\")\n",
    "    print(f\"Effect size (Cohen's d): {cohens_d:.4f}\")\n",
    "    \n",
    "    if mw_pvalue < 0.05:\n",
    "        print(\"✓ HYPOTHESIS SUPPORTED: Selected weights are significantly smaller than other weights\")\n",
    "    else:\n",
    "        print(\"✗ HYPOTHESIS NOT SUPPORTED: No significant difference found\")\n",
    "    \n",
    "    # Return results dictionary\n",
    "    results = {\n",
    "        'selected_stats': {\n",
    "            'mean': np.mean(selected_weights),\n",
    "            'median': np.median(selected_weights),\n",
    "            'std': np.std(selected_weights),\n",
    "            'n': len(selected_weights)\n",
    "        },\n",
    "        'other_stats': {\n",
    "            'mean': np.mean(other_weights),\n",
    "            'median': np.median(other_weights),\n",
    "            'std': np.std(other_weights),\n",
    "            'n': len(other_weights)\n",
    "        },\n",
    "        'tests': {\n",
    "            'mann_whitney_u': {'statistic': mw_statistic, 'pvalue': mw_pvalue},\n",
    "            'welch_t_test': {'statistic': t_statistic, 'pvalue': t_pvalue_one_tailed},\n",
    "            'ks_2sample': {'statistic': ks2_statistic, 'pvalue': ks2_pvalue},\n",
    "            'cohens_d': cohens_d\n",
    "        },\n",
    "        'hypothesis_supported': mw_pvalue < 0.05\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "######### EXTRACT OUTGOING WEIGHTS ##########\n",
    "save_outgoing_weights = False\n",
    "if save_outgoing_weights:\n",
    "    print(\"Extracting outgoing weights for sampled neurons...\")\n",
    "    \n",
    "    # Find the source layer (blocks.2.convs.0) that we're sampling from\n",
    "    source_layer_name = None\n",
    "    source_layer_module = None\n",
    "    \n",
    "    # Find the target layer (blocks.2.convs.1) to extract outgoing weights from\n",
    "    target_layer_name = None\n",
    "    target_layer_module = None\n",
    "    \n",
    "    for name, module in model.named_modules():\n",
    "        if 'blocks.2.convs.0' in name and isinstance(module, fnn.model.elements.Conv):\n",
    "            source_layer_name = name\n",
    "            source_layer_module = module\n",
    "            print(module)\n",
    "            print(f\"Found source layer (sampling from): {source_layer_name}\")\n",
    "        elif 'blocks.2.convs.1' in name and isinstance(module, fnn.model.elements.Conv):\n",
    "            target_layer_name = name\n",
    "            target_layer_module = module\n",
    "            print(f\"Found target layer (outgoing weights): {target_layer_name}\")\n",
    "    \n",
    "    if target_layer_module is None:\n",
    "        print(\"Warning: Could not find blocks.2.convs.1 layer for outgoing weight extraction\")\n",
    "        outgoing_weights = None\n",
    "    else:\n",
    "        # Get the weight tensor from the target conv layer (blocks.2.convs.1)\n",
    "        # Shape: (out_channels, in_channels, kernel_height, kernel_width)\n",
    "        print(target_layer_module.weights[0].shape)\n",
    "        layer_weights = np.reshape(np.stack((\n",
    "            target_layer_module.weights[0].detach().cpu().numpy(),\n",
    "            target_layer_module.weights[1].detach().cpu().numpy(),\n",
    "            target_layer_module.weights[2].detach().cpu().numpy(),\n",
    "            target_layer_module.weights[3].detach().cpu().numpy()\n",
    "        )), (512, 32, 3, 3, 3))\n",
    "        print(f\"Target layer weights shape: {layer_weights.shape}\")\n",
    "\n",
    "        idx = [212,101, 114, 754, 121, 100, 466, 120, 108, 1313, 934, 588, 144, 776, 129,502,122,229,753,102,788,16,1321,785,787,523,44,390,116,213,1162,543,592,214,579,550,1986,342,935,235,234,143,217,562,760,752,46,775,185,204,236,598,583,964,951,219,501,200,1950,1241,148,927,792,1594,967,497,1649,463,493,793,1619,380,241,1623,821,1060,829,1623,1959,714,858,1632,766,1238,1179,392,1621,780,228,345,1982,194]\n",
    "        #idx = list(range(1000, 2000))\n",
    "        inhibitory_weigths = []\n",
    "        inhibitory_fmaps = []\n",
    "        other_weights = []\n",
    "        done = []\n",
    "        for nii, ni in enumerate(sampled_neurons):\n",
    "            li, fi, ii, jj, posi = get_neuron_pos(ni)\n",
    "            if nii in idx and fi not in inhibitory_fmaps:\n",
    "                inhibitory_fmaps.append(fi)\n",
    "            #print(f\"li={li}\")\n",
    "        for nii, ni in enumerate(sampled_neurons):\n",
    "            li, fi, ii, jj, posi = get_neuron_pos(ni)\n",
    "            if fi not in done:\n",
    "                if fi in inhibitory_fmaps:\n",
    "                    inhibitory_weigths.append(layer_weights[fi])\n",
    "                else:\n",
    "                    other_weights.append(layer_weights[fi])\n",
    "                done.append(fi)\n",
    "        print(len(inhibitory_weigths))\n",
    "        print(len(other_weights))\n",
    "\n",
    "        compare_weight_distributions(inhibitory_weigths, other_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_pos:\n",
    "    block[block == 'recurrent.out'] = 'position'\n",
    "for i in range(len(block)):\n",
    "    block[i] = block[i].replace('.', '')\n",
    "SUFFIX = f\"{model_name}_{LAYER_TYPE}_i{N_INSTANCES}_n{n_neurons_to_pick}_SCL{str(scl_factor).replace('.', '_')}_TL{trial_len}_{'_'.join(block)}_{fmap_samp_method}_{neur_samp_method}\"\n",
    "if samp_max_one_dir:\n",
    "    SUFFIX += '_onedir'\n",
    "if seed > 0:\n",
    "    SUFFIX += f'_seed{seed}'\n",
    "\n",
    "print(SUFFIX)\n",
    "\n",
    "directory = '../data/sampled_data'\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "if os.path.exists(f'../data/sampled_data/tensor4d_{SUFFIX}.npy'):\n",
    "    print(\"Files already exist, please delete them to prevent conflicts.\")\n",
    "else:\n",
    "    \n",
    "    np.save(f'../data/sampled_data/tensor4d_{SUFFIX}.npy', tensorX)\n",
    "    print(f'tensor4d_{SUFFIX}.npy Saved.')\n",
    "\n",
    "    np.save(f'../data/sampled_data/neurons_used_{SUFFIX}.npy', neurons_used)\n",
    "    print(f'neurons_used_{SUFFIX}.npy Saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
